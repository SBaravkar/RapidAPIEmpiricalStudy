{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d38bf563",
   "metadata": {},
   "source": [
    "### Import all necesaary packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd21e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import session\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from urllib.parse import urlparse\n",
    "from requests.exceptions import HTTPError\n",
    "import mysql.connector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6896989b",
   "metadata": {},
   "source": [
    "### Find all API categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e3a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = 'https://rapidapi.com/categories'\n",
    "with session() as s:\n",
    "    r1 = s.get(API_URL)\n",
    "\n",
    "soup = bs(r1.text, 'html.parser')\n",
    "htmlText = soup.prettify()\n",
    "API_Categories= soup.find_all('div',{'CollectionCarousel CollectionCarousel'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872ea69",
   "metadata": {},
   "source": [
    "### Get all API category links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0afaf0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No match found.\n"
     ]
    }
   ],
   "source": [
    "# Parse the HTML content\n",
    "soup_all_categories = bs(r1.text, 'html.parser')\n",
    "\n",
    "# Find the <a> tag with the specified class\n",
    "a_tags = soup.find_all('a', class_='CardLink')\n",
    "href_values = []\n",
    "categories = []\n",
    "if a_tags:\n",
    "    for a_tag in a_tags:\n",
    "        href_value = a_tag.get('href')\n",
    "        href_values.append(href_value)\n",
    "        category = a_tag.text.strip()\n",
    "        categories.append(category)      \n",
    "else:\n",
    "    print('No match found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6171f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if href_values:\n",
    "    href_value = [\"https://rapidapi.com\" + href for href in href_values]    \n",
    "    api_href_pairs = list(zip(categories, href_value))\n",
    "    print(api_href_pairs)\n",
    "else:\n",
    "    print('No href value found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657c90c",
   "metadata": {},
   "source": [
    "### Get API links for each category link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')  # Run Chrome in headless mode, without opening a window\n",
    "\n",
    "user_data_dir = r'C:\\xxx\\AppData\\Local\\Google\\Chrome\\User Data'\n",
    "\n",
    "webdriver_path = 'D:\\chromedriver_win32\\chromedriver.exe'  # Replace with the actual path to the chromedriver executable\n",
    "\n",
    "options.add_argument(f'--user-data-dir={user_data_dir}')\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=webdriver_path, options=options)\n",
    "\n",
    "#for x in href_value:\n",
    "    #print(x)\n",
    "    # Load the initial URL\n",
    "driver.get('https://rapidapi.com/category/News,%20Media')\n",
    "base_urls = []\n",
    "def scrape_page(url):\n",
    "    soup = bs(driver.page_source, 'html.parser')\n",
    "    a_tags = soup.find_all('a', class_='CardLink')\n",
    "    if a_tags:\n",
    "        for a_tag in a_tags:\n",
    "            base_url = \"https://rapidapi.com\" + a_tag.get('href')\n",
    "            base_urls.append(base_url)\n",
    "def scrape_all_pages(base_url):\n",
    "     while True:\n",
    "        scrape_page(driver.current_url)\n",
    "        next_button = None\n",
    "        try:\n",
    "            next_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'r-page-link') and contains(text(),'â€º') and not(@disabled)]\")))\n",
    "            driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "            WebDriverWait(driver, 10).until(EC.staleness_of(next_button))\n",
    "        except:\n",
    "            if next_button is None:\n",
    "                break\n",
    "\n",
    "scrape_all_pages('https://rapidapi.com/category/News,%20Media')\n",
    "driver.quit()  # Close the browser after scraping    \n",
    "\n",
    "# Print the scraped URLs\n",
    "for url in base_urls:\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a504b7",
   "metadata": {},
   "source": [
    "### Get Details from Pricing Page \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f09eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_details = {}\n",
    "\n",
    "for base_url in base_urls:\n",
    "    print(base_url)\n",
    "    try:\n",
    "        r4 = s.get(base_url + \"pricing\")\n",
    "    except TimeoutException:\n",
    "        pricing = 'No pricing details available'\n",
    "        print(pricing)\n",
    "    soup4 = bs(r4.text, 'html.parser')\n",
    "    plan_names = []\n",
    "    plan_requests = []\n",
    "    plan_costs = []\n",
    "\n",
    "    plan_name_elements = soup4.find_all(\"h2\", class_=\"PlanName\")\n",
    "    plan_request_elements = soup4.find_all(\"div\", class_=\"LimitQuotaRow bold\")\n",
    "    plan_cost_per_req_elements = soup4.find_all(\"div\", class_=\"LimitOverageRow caption\")\n",
    "#     td_element = soup4.find('td', class_='PlanDetailCell').text.strip()\n",
    "#     if \"requests per\" in td_element:\n",
    "#         plan_request_elements = re.search(r'\\b(\\d+)\\b', td_element)\n",
    "#         if plan_request_elements:\n",
    "#             plan_request_elements = plan_request_elements.group(1)\n",
    "\n",
    "#     print(plan_request_elements)   \n",
    "\n",
    "    \n",
    "    # Initialize variables\n",
    "    basic = None\n",
    "    pro = None\n",
    "    ultra = None\n",
    "    mega = None\n",
    "    basic_cost_per_req = None\n",
    "    pro_cost_per_req = None\n",
    "    ultra_cost_per_req = None\n",
    "    mega_cost_per_req = None\n",
    "    hard_limit = None\n",
    "\n",
    "    for plan_name_element, plan_request_element, plan_cost_per_req_element in zip(plan_name_elements, plan_request_elements, plan_cost_per_req_elements):\n",
    "        plan_name = plan_name_element.text.strip()\n",
    "        plan_cost_per_req = plan_cost_per_req_element.text.strip()\n",
    "        plan_request = plan_request_element.text.strip()\n",
    "        print(plan_request)\n",
    "        plan_names.append(plan_name)\n",
    "        plan_requests.append(plan_request)\n",
    "        parts = plan_cost_per_req.split('$')\n",
    "            \n",
    "        if len(parts) == 2:\n",
    "            print(parts)\n",
    "            plan_cost_per_req = float(parts[1].split()[0].replace(',', ''))\n",
    "            \n",
    "            plan_costs.append(plan_cost_per_req)               \n",
    "\n",
    "        else:\n",
    "            plan_cost_per_req = 0\n",
    "            plan_costs.append(plan_cost_per_req)\n",
    "                \n",
    "    if len(plan_costs) == 0 and len(plan_requests) == 0:\n",
    "        pricing_details[base_url] = {\n",
    "            'basic_req': basic,\n",
    "            'pro_req': pro,\n",
    "            'ultra_req': ultra,\n",
    "            'mega_req': mega,\n",
    "            'basic_per_req_cost': basic_cost_per_req,\n",
    "            'pro_per_req_cost': pro_cost_per_req,\n",
    "            'ultra_per_req_cost': ultra_cost_per_req,\n",
    "            'mega_per_req_cost': mega_cost_per_req\n",
    "        }\n",
    "        \n",
    "    # Iterate over plan_names to set variables\n",
    "    for name, request, cost in zip(plan_names, plan_requests, plan_costs):\n",
    "        if \"Basic\" in name:\n",
    "            basic_cost_per_req = cost\n",
    "            if ',' in request:\n",
    "                request = request.replace(',', '')\n",
    "            basic = int(request.split('/')[0].strip())\n",
    "            if \"month\" in request:\n",
    "                basic = basic/30\n",
    "        elif \"Pro\" in name:\n",
    "            pro_cost_per_req = cost\n",
    "            if ',' in request:\n",
    "                request = request.replace(',', '')\n",
    "            pro = int(request.split('/')[0].strip())\n",
    "            if \"month\" in request:\n",
    "                pro = pro/30\n",
    "        elif \"Ultra\" in name:\n",
    "            ultra_cost_per_req = cost\n",
    "            if ',' in request:\n",
    "                request = request.replace(',', '')\n",
    "            ultra = int(request.split('/')[0].strip())\n",
    "            if \"month\" in request:\n",
    "                ultra = ultra/30\n",
    "        elif \"Mega\" in name:\n",
    "            mega_cost_per_req = cost\n",
    "            if ',' in request:\n",
    "                request = request.replace(',', '')\n",
    "            mega = int(request.split('/')[0].strip())\n",
    "            if \"month\" in request:\n",
    "                mega = mega/30\n",
    "\n",
    "        # Store pricing details for the current base_url\n",
    "        pricing_details[base_url] = {\n",
    "            'basic_req': basic,\n",
    "            'pro_req': pro,\n",
    "            'ultra_req': ultra,\n",
    "            'mega_req': mega,\n",
    "            'basic_per_req_cost': basic_cost_per_req,\n",
    "            'pro_per_req_cost': pro_cost_per_req,\n",
    "            'ultra_per_req_cost': ultra_cost_per_req,\n",
    "            'mega_per_req_cost': mega_cost_per_req\n",
    "        }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc4885",
   "metadata": {},
   "source": [
    "### Upload to Table api_pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f942d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# Connect to MySQL\n",
    "cnx = mysql.connector.connect(\n",
    "    host='xxx',\n",
    "    user='xxx',\n",
    "    password='xxx',\n",
    "    database='rapAPI2'\n",
    ")\n",
    "\n",
    "cursor = cnx.cursor()\n",
    "\n",
    "# Prepare the SQL statement for the insert operation\n",
    "insert_endpoint_details = \"INSERT INTO api_pricing (base_url, basic_req, pro_req, ultra_req, mega_req, \" \\\n",
    "                          \"basic_per_req_cost, pro_per_req_cost, ultra_per_req_cost, mega_per_req_cost) \" \\\n",
    "                          \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "# Iterate over the items in the api_details dictionary\n",
    "for base_url, details in pricing_details.items():\n",
    "    base_url = base_url[:255]\n",
    "    basic_req = details['basic_req']\n",
    "    pro_req = details['pro_req']\n",
    "    ultra_req = details['ultra_req']\n",
    "    mega_req =  details['mega_req']\n",
    "    basic_per_req_cost = details['basic_per_req_cost']\n",
    "    pro_per_req_cost = details['pro_per_req_cost']\n",
    "    ultra_per_req_cost = details['ultra_per_req_cost']\n",
    "    mega_per_req_cost = details['mega_per_req_cost']\n",
    "\n",
    "    # Check if URL already exists in the database\n",
    "    select_query = \"SELECT base_url FROM api_pricing WHERE base_url = %s\"\n",
    "    cursor.execute(select_query, (base_url,))\n",
    "    existing_url = cursor.fetchone()\n",
    "\n",
    "    if existing_url:\n",
    "        print(f\"URL {base_url} already exists in the database. Skipping insertion.\")\n",
    "    else:\n",
    "        # Execute the insert operation for each URL and details\n",
    "        cursor.execute(insert_endpoint_details, (base_url, basic_req, pro_req, ultra_req, mega_req, basic_per_req_cost,\n",
    "                                                pro_per_req_cost, ultra_per_req_cost, mega_per_req_cost))\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "cnx.commit()\n",
    "cnx.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
